00:00 Mujer: Hola y bienvenidas y bienvenidos. Hoy vamos a analizar un material con un título, eh, que es casi una provocación: "Tus registros de software te están mintiendo".
00:11 Hombre: Y ojo, no se refiere a que mientan con mala intención. Es algo peor: la idea es que son, pues, fundamentalmente inútiles para el software de hoy en día. Todos los que nos dedicamos a esto hemos vivido esa escena casi de terror: son las tres de la madrugada, salta una alerta en producción y tu única pista es un mar de líneas de texto que no entiendes. Yo recuerdo una noche que me pasé seis horas buscando un bug, seis horas, solo para darme cuenta de que el problema venía de un servicio que ni sabía que existía, porque claro, los logs no se hablaban entre sí. Acabé buscando por el importe exacto del carrito de la compra en céntimos, un desastre. Pues hoy vamos a desgranar por qué este caos es la norma y, sobre todo, qué se puede hacer.
00:53 Mujer: Esa historia que cuentas es que es el pan de cada día para muchísima gente. Y el problema de fondo que el artículo señala muy bien es que estamos usando una herramienta del siglo XX para problemas del siglo XXI. Los registros se inventaron para aplicaciones que vivían en un solo servidor: un programa, una máquina, un archivo de texto. Sencillo, ¿no?
01:17 Hombre: Sí, muy simple.
01:18 Mujer: Pero es que hoy un solo clic en "comprar" puede desencadenar una reacción en cadena que toque 20 microservicios, tres bases de datos, cuatro cachés... y nuestros registros siguen siendo, en esencia, ese mismo archivo de texto. Pero ahora es un puzle de mil piezas esparcidas por toda la casa: falta el pegamento, falta el contexto.
01:41 Hombre: Exactamente. Vamos a empezar por ahí, por el problema fundamental. El autor lo describe de una forma que a mí me pareció genial: dice que buscar en los registros es como jugar a los detectives con una mano atada a la espalda. Un cliente llama, dice que no puede pagar. Lo primero que haces, claro, buscar su ID de usuario, pongamos user123.
02:02 Mujer: Lo lógico.
02:03 Hombre: Y ahí empieza el infierno, porque en un servicio lo vas a encontrar como user123, en otro user_id = user123, o en un tercero será un JSON con "user_id": "user123".
02:14 Mujer: Exacto.
02:15 Hombre: Y eso si tienes suerte y lo encuentras, porque a lo mejor el servicio de pagos solo sabe del ID del pedido, no del usuario. Así que ahora te toca buscar el ID de ese pedido en otro sistema para poder relacionarlo. O sea, antes de que te des cuenta tienes cinco ventanas de terminal abiertas y estás intentando atar cabos a mano. Te vuelves loco. Justo esa es la madre del cordero, y el artículo lo resume en una idea que es clave: los registros están optimizados para la escritura, no para la consulta.
02:46 Mujer: "Para la escritura, no para la consulta". Para quien desarrolla es insultantemente fácil escribir console.log("pago fallido"). Es un acto reflejo, casi un tic. Pero esa línea, así aislada, no le sirve de nada a la persona que tiene que arreglar el marrón a las dos de la mañana con la presión de que el negocio está perdiendo dinero.
03:09 Hombre: Claro, no sabe nada.
03:10 Mujer: No sabe quién era, qué compraba, desde dónde, ni por qué falló exactamente. Es como un grito en mitad de la noche.
03:18 Hombre: Claro. Es que visto así es evidente: es facilísimo añadir ruido, pero casi imposible añadir una señal que sea clara. Vale, si ese es el problema, el artículo propone una solución, pero para entenderla usa un lenguaje muy específico. Antes de seguir, creo que tenemos que aclarar qué significan exactamente "cardinalidad" o eso que llama un "evento amplio", ¿no te parece?
03:45 Mujer: Totalmente de acuerdo, son los cimientos de la propuesta. A ver, el primer concepto, el más básico, es el registro estructurado, el structured logging. Esto es simplemente dejar de escribir texto libre y empezar a emitir registros en un formato de clave-valor, casi siempre JSON.
04:02 Hombre: En lugar de "Fallo en el pago para el usuario 123", ¿exacto? Escribiríamos algo como: evento: "fallo pago", user_id: 123. Este es el punto de partida, es indispensable. Pero ojo, y esto es importante, no es la solución. Es como tener los ladrillos, todavía hay que construir la casa.
04:22 Mujer: Vale, eso se entiende. Es pasar de un diario a una hoja de cálculo, por decirlo de alguna manera. ¿Qué más?
04:30 Hombre: Luego vienen dos ideas que van de la mano: cardinalidad y dimensionalidad. Suenan un poco intimidantes, pero son conceptos sencillos.
04:40 Mujer: La cardinalidad es el número de valores únicos que puede tener un campo. Por ejemplo, el campo http_method tiene baja cardinalidad: solo puede ser GET, POST, PUT... unos pocos valores.
04:52 Hombre: Mientras que un campo como user_id o cart_id tiene una cardinalidad altísima porque puede haber millones de usuarios o de carritos distintos.
04:59 Mujer: Exacto, y ahí está la clave: los datos que de verdad son útiles para depurar son los de alta cardinalidad, los que te permiten aislar una transacción o un usuario concreto.
05:12 Hombre: Vale.
05:13 Mujer: Y la dimensionalidad es aún más fácil: es simplemente el número de campos o dimensiones que tiene tu registro. Un log con cinco campos tiene baja dimensionalidad, uno con cincuenta pues alta. Cuantas más dimensiones, más preguntas puedes hacerle a tus datos.
05:30 Hombre: Entendido. Ladrillos que es el JSON, datos únicos que es la alta cardinalidad y muchos tipos de datos distintos que es la alta dimensionalidad. Y con todo eso, ¿qué construimos? Construimos el concepto central de todo el artículo: el evento amplio, el wide event. O como también lo llama citando a Stripe: la línea de registro canónica.
05:56 Mujer: La idea es un cambio de paradigma. En lugar de escupir docenas de líneas de registro pequeñas e inconexas durante una petición, lo que haces es construir y emitir un único y gran evento al final de cada operación importante.
06:11 Hombre: ¿Uno solo?
06:12 Mujer: Uno solo, pero que contenga todo el contexto relevante. Es que el artículo tiene una frase que cuando la leí me explotó la cabeza. Dice: "En lugar de registrar lo que tu código está haciendo, registra lo que le pasó a esta solicitud". Es un cambio de mentalidad brutal, sí.
06:31 Hombre: Dejas de escribir un diario de depuración para tu "yo" del futuro y empiezas a generar un registro de auditoría de eventos de negocio. Y eso es infinitamente más valioso. De hecho, el ejemplo que ponen de un evento amplio para un pago que falla es increíblemente revelador. No es una línea, es casi la biografía completa de la transacción.
06:54 Mujer: A ver, vamos a reconstruirlo. Por un lado tienes la información técnica básica: request_id, trace_id, el nombre del servicio, la versión, la duración, el status_code... bueno, lo normal.
07:07 Hombre: Sí, esa es la base.
07:08 Mujer: Pero ahora viene la magia: a ese mismo evento le añades el contexto del negocio. Por ejemplo, el contexto del usuario: su ID, user456, pero también que su suscripción es premium, que lleva 800 días como cliente y que su valor de vida para la empresa es de, no sé, 5000 euros.
07:28 Hombre: Vaya. De repente ya no es un usuario anónimo, es un cliente VIP.
07:33 Mujer: Exacto. Y no solo eso, también metes el contexto del negocio: el carrito que llevaba cinco artículos por 120 euros y que había usado un cupón de descuento.
07:44 Hombre: Y luego el contexto del error, que es crucial: no solo un genérico "pago fallido", sino el tipo de error payment_error, el código card_declined, el mensaje exacto del banco "fondos insuficientes", si se puede reintentar o no... e incluso el código interno de la pasarela de pago stripe_decline_code: insufficient_funds. Uff. Espera, que falta la guinda del pastel: el contexto de la aplicación. Un campo con las feature flags, las funcionalidades experimentales que estaban activas para ese usuario en ese momento, como por ejemplo new_checkout_flow: true.
08:24 Mujer: Eso, justo a eso iba. Espera un momento, ¿me estás diciendo que en esa única línea de log, en ese único JSON, yo sabría que un cliente premium de los importantes intentó hacer una compra grande que le falló por falta de fondos y que además estaba usando la nueva versión del checkout que acabamos de desplegar?
08:44 Hombre: Exactamente eso. Todo en una sola búsqueda por user456. Se acabaron las conjeturas, las correlaciones a mano y las cinco ventanas de terminal. Tienes la historia completa en un solo lugar. Esto transforma la depuración de ser un trabajo de detective a ser un trabajo de analista de datos. Ya no buscas texto, haces consultas. Claro, es que la pregunta que puedes hacer cambia radicalmente. En vez de buscar user456 y rezar, ahora puedes preguntar: "Oye, sistema, muéstrame todos los fallos de pago para usuarios premium en la última hora donde la feature flag del nuevo checkout estaba activa y agrúpamelo por el código de error del banco". La diferencia es...
09:34 Mujer: Es que es otro deporte. Es la diferencia entre buscar una aguja en un pajar y pedirle a Google la dirección de la tienda de agujas. Pasas de un enfoque reactivo y manual a uno proactivo y analítico. Podrías tener un dashboard que te alerte si de repente la tasa de error para usuarios con el nuevo checkout se dispara un 5% para un banco concreto. Es... es un cambio de juego.
10:00 Hombre: Vale, esto en teoría suena increíble, pero mi primer pensamiento como ingeniera es que esto tiene que costar un dineral. Si guardas un JSON gigante con cincuenta campos por cada una de las miles de peticiones por segundo que puedes tener... los de finanzas ya llaman a la puerta. Claro, el coste de almacenamiento y de procesamiento tiene que ser prohibitivo.
10:23 Mujer: Es la objeción más lógica y la primera que se le ocurre a todo el mundo. Y el artículo la aborda de frente, porque si no toda esta idea sería inviable. La solución no es registrarlo todo, sino ser inteligente sobre qué guardas. La técnica clave es el muestreo, el sampling.
10:41 Hombre: Muestreo... pero de un tipo muy particular, el muestreo de cola o tail sampling.
10:49 Mujer: ¿Muestreo de cola? ¿Eso qué significa? ¿Que solo miras el final?
10:53 Hombre: Casi. Significa que la decisión de guardar o descartar el evento completo no la tomas al principio de la petición, sino al final, cuando ya sabes cómo ha terminado todo. Esto implica tener un componente en tu infraestructura, un colector, que retiene en memoria los datos de la petición durante unos segundos. Y una vez que la petición termina y tienes el resultado final, si fue un error, si fue lenta, si fue exitosa... este colector aplica unas reglas para decidir si la guarda para siempre o la tira.
11:24 Mujer: Ah, vale. O sea, esperas a tener toda la información para decidir si la información es valiosa. ¿Y cuáles son esas reglas? Las que propone el artículo son de sentido común y muy potentes. Primero: guardar siempre los errores. El 100% de las peticiones que terminen en error, un código 500, una excepción... se guardan. Siempre. Lógico.
11:46 Hombre: Totalmente.
11:47 Mujer: Segundo: guardar siempre las lentas. Todo lo que supere un umbral de latencia, por ejemplo, lo que esté por encima del percentil 99, se guarda. La lentitud se odia tanto como los errores.
11:59 Hombre: Totalmente.
12:00 Mujer: Tercero: guardar siempre las de usuarios específicos. Puedes tener una lista de clientes VIP, cuentas de prueba internas... y guardar todas sus peticiones para investigar sus problemas a fondo.
12:12 Hombre: Vale. ¿Y la clave para el coste?
12:15 Mujer: Cuarto: muestrear aleatoriamente un pequeño porcentaje del resto. De todo lo demás, que son las peticiones rápidas y exitosas, el 99% del tráfico... de esas solo guardas una pequeña muestra, entre el 1 y el 5%. O sea, que te quitas de enmedio el 95% del ruido de las peticiones que funcionan bien, que no suelen interesar, pero te aseguras al 100% de que no pierdes ni un solo evento que apunte a un problema.
12:41 Hombre: Exacto. Tienes lo mejor de los dos mundos: visibilidad total de los fallos y costes controlados. Es bastante ingenioso. Pagas por la señal, no por el ruido. Aun así, un momento, porque a mí esto me sigue sonando un poco a cosas que ya se intentan hacer. Por ejemplo, me suena mucho a lo que llamamos registro estructurado. Ya mandamos JSONs, usamos claves... ¿En dónde está la diferencia real, más allá del nombre?
13:06 Mujer: Es una duda muy común y la distinción es crucial. El registro estructurado es el formato, es el "qué": usar JSON. Los eventos amplios son la filosofía, el "cómo": consolidar todo el contexto de una operación de negocio en un único evento. Puedes estar haciendo un registro estructurado perfecto y que siga siendo inútil, porque tienes 20 líneas JSON distintas para una sola petición, sin un ID que las conecte y sin el contexto de negocio del que hablábamos.
13:34 Hombre: O sea, que el registro estructurado es una condición necesaria pero no suficiente.
13:38 Mujer: Exacto.
13:39 Hombre: Vale, entendido. No es el formato, es la estrategia de agrupar la información. Pero entonces, ¿qué pasa con todo el ecosistema de OpenTelemetry? Con todo el bombo que se le está dando, ¿no resuelve esto ya? Yo pensaba que era la panacea para la observabilidad.
13:55 Mujer: OpenTelemetry es una herramienta fantástica. De hecho, es el vehículo perfecto para implementar esta filosofía. Pero es solo eso, un vehículo. El artículo lo define muy bien: es un mecanismo de entrega estandarizado. Te da las tuberías, los protocolos, las APIs para que tus datos viajen de tus aplicaciones a tu sistema de análisis.
14:16 Hombre: Pero no decide qué datos van por las tuberías.
14:19 Mujer: Justo. OpenTelemetry no sabe qué es un usuario premium o cuál es el valor de un carrito. Ese contexto de negocio lo tiene que añadir deliberadamente la persona que desarrolla el código, con intención. OpenTelemetry transporta los paquetes, pero tú decides qué metes dentro.
14:36 Hombre: Entiendo. Es el fontanero, no el agua. Y la última duda que me surgió: todo esto de seguir una petición a través de varios servicios... ¿No es simplemente tracing o trazado distribuido con otro nombre?
14:52 Mujer: Son complementarios. De hecho, la combinación ideal es que tus trazas sean tus eventos amplios. Piénsalo así: el tracing te da el mapa del viaje, el flujo.
15:03 Hombre: Eso es.
15:04 Mujer: Te dice que una petición empezó en el servicio A, luego llamó al B y el B a la base de datos C. Te muestra el esqueleto. Los eventos amplios, en cambio, son las fotos y el diario de viaje de cada parada. Te dan el contexto profundo dentro del servicio B: qué usuario era, qué hacía, con qué datos trabajó y por qué tardó tanto.
15:23 Hombre: Ah, claro. Lo ideal es tener las dos cosas: la traza que conecta los servicios y, en cada paso de esa traza, un evento amplio que te cuente todo lo que pasó ahí dentro. Queda clarísimo. Entonces, si tuviéramos que resumirlo todo, estamos hablando de dejar de ver los registros como una especie de... de arqueología digital, donde excavas entre ruinas de texto con la esperanza de encontrar una pista.
15:46 Mujer: Sí, es una buena analogía. La idea es pasar a verlos como lo que deberían ser: una herramienta de análisis de datos potentísima y en tiempo real. Y la clave para eso es el cambio de mentalidad: el esfuerzo deliberado de capturar el contexto completo de cada operación de negocio en un único lugar. Exactamente eso, has dado en el clavo. Es un cambio de disciplina: es tratar la observabilidad como una funcionalidad de primera clase, no como algo que se añade al final con prisas. Y esto me lleva a una reflexión final que se desprende de todo esto: hemos visto cómo un solo evento bien pensado y rico en contexto puede reemplazar miles de líneas de registro inútiles y de paso reducir costes con un muestreo inteligente.
16:33 Hombre: Sí. La pregunta que me queda flotando es: si en el logging hemos estado confundiendo "más datos" con "más información", ¿en qué otras áreas del desarrollo de software seguimos aferrados a esa misma idea de que "más es mejor"? Más funcionalidades, más líneas de código...
16:51 Mujer: Más microservicios... cuando la verdadera clave podría estar en hacer las cosas de una forma más inteligente, más cohesionada y, sobre todo, con más contexto.
17:01 Hombre: Uff, esa es una pregunta excelente para darle una vuelta. Nos la quedamos para reflexionar. Muchísimas gracias por acompañarnos en este análisis. Hasta la próxima.