<?php
/**
 * Script de ingesta RAG - Procesa UN archivo por llamada
 * Recarga la pÃ¡gina para procesar el siguiente archivo
 * Â¡ELIMINAR DESPUÃ‰S DE USAR!
 */

set_time_limit(120); // 2 minutos max por archivo
ini_set('memory_limit', '256M');

require_once __DIR__ . '/../../../src/App/bootstrap.php';
require_once __DIR__ . '/../../../src/Rag/QdrantClient.php';
require_once __DIR__ . '/../../../src/Rag/EmbeddingService.php';

use App\Env;
use Rag\QdrantClient;
use Rag\EmbeddingService;

// ConfiguraciÃ³n
define('COLLECTION_NAME', 'lex_convenios');
define('VECTOR_SIZE', 4096);
define('CHUNK_SIZE', 1000); // Aumentado para artÃ­culos mÃ¡s largos
define('CHUNK_OVERLAP', 100);
define('BATCH_SIZE', 2); // Reducido un poco para compensar chunks mÃ¡s grandes

$conveniosPath = __DIR__ . '/../../../docs/context/voices/lex/convenios';
$progressFile = sys_get_temp_dir() . '/lex_ingest_progress.json';

// Leer progreso
$progress = file_exists($progressFile) ? json_decode(file_get_contents($progressFile), true) : [];
$processedFiles = $progress['processed'] ?? [];
$pointId = $progress['pointId'] ?? 1;
$totalChunks = $progress['totalChunks'] ?? 0;

// Reset si se pide
if (isset($_GET['reset'])) {
    @unlink($progressFile);
    
    // TambiÃ©n intentar borrar la colecciÃ³n en Qdrant para limpieza total
    try {
        $qdrantHost = Env::get('QDRANT_HOST', 'localhost');
        $qdrantPort = (int) Env::get('QDRANT_PORT', 6333);
        $qdrant = new Rag\QdrantClient($qdrantHost, $qdrantPort);
        if ($qdrant->collectionExists(COLLECTION_NAME)) {
            $qdrant->deleteCollection(COLLECTION_NAME);
        }
    } catch (\Exception $e) {
        // Ignorar errores aquÃ­, el reset de archivos es lo principal
    }

    header('Location: ' . strtok($_SERVER['REQUEST_URI'], '?'));
    exit;
}

// HTML
echo "<!DOCTYPE html><html><head><meta charset='UTF-8'><title>Ingesta RAG</title>";
echo "<meta http-equiv='refresh' content='3'>"; // Auto-refresh cada 3s
echo "<style>body{font-family:system-ui;max-width:800px;margin:40px auto;padding:20px;background:#0d1117;color:#c9d1d9}";
echo "pre{background:#161b22;padding:20px;border-radius:8px;overflow-x:auto}";
echo ".ok{color:#3fb950}.err{color:#f85149}.warn{color:#d29922}a{color:#58a6ff}</style></head><body>";

echo "<h1>ðŸ”„ Ingesta RAG para Lex</h1>";

try {
    // Verificar API key
    $openrouterKey = Env::get('OPENROUTER_API_KEY');
    if (!$openrouterKey) {
        throw new Exception("OPENROUTER_API_KEY no configurada");
    }

    // Conectar Qdrant
    $qdrantHost = Env::get('QDRANT_HOST', 'localhost');
    $qdrantPort = (int) Env::get('QDRANT_PORT', 6333);
    $qdrant = new QdrantClient($qdrantHost, $qdrantPort);
    $embeddings = new EmbeddingService($openrouterKey);

    if (!$qdrant->health()) {
        throw new Exception("No se puede conectar con Qdrant en {$qdrantHost}:{$qdrantPort}");
    }

    // Crear colecciÃ³n si no existe
    if (!$qdrant->collectionExists(COLLECTION_NAME)) {
        $qdrant->createCollection(COLLECTION_NAME, VECTOR_SIZE, 'Cosine');
        echo "<p class='ok'>âœ“ ColecciÃ³n creada</p>";
    }

    // Buscar archivos pendientes
    $txtFiles = glob($conveniosPath . '/*.txt');
    $files = array_filter($txtFiles, fn($f) => basename($f) !== 'README.md');
    $files = array_values($files);
    
    $pending = array_filter($files, fn($f) => !in_array(basename($f), $processedFiles));
    $pending = array_values($pending);

    $total = count($files);
    $done = count($processedFiles);

    echo "<h2>Progreso: {$done}/{$total} archivos</h2>";
    echo "<progress value='{$done}' max='{$total}' style='width:100%;height:30px'></progress>";

    if (empty($pending)) {
        // Terminado
        echo "<pre>";
        echo "<span class='ok'>âœ… INGESTA COMPLETADA</span>\n\n";
        echo "Archivos procesados: {$done}\n";
        echo "Total chunks indexados: {$totalChunks}\n";
        $count = $qdrant->countPoints(COLLECTION_NAME);
        echo "Puntos en colecciÃ³n: {$count}\n";
        echo "</pre>";
        echo "<p><a href='?reset=1'>ðŸ”„ Reiniciar ingesta</a></p>";
        echo "<p><strong>Ahora borra este archivo: public/api/voices/ingest_lex_web.php</strong></p>";
        // Quitar auto-refresh
        echo "<script>document.querySelector('meta[http-equiv]').remove();</script>";
        exit;
    }

    // Procesar siguiente archivo
    $file = $pending[0];
    $filename = basename($file);
    
    echo "<pre>";
    echo "â†’ Procesando: <strong>{$filename}</strong>\n";

    $text = file_get_contents($file);
    // Limpiar caracteres problemÃ¡ticos para JSON
    $text = preg_replace('/[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]/', ' ', $text);
    $text = mb_convert_encoding($text, 'UTF-8', 'UTF-8');
    // Eliminar caracteres no UTF-8 vÃ¡lidos
    $text = iconv('UTF-8', 'UTF-8//IGNORE', $text);
    // Normalizar espacios y saltos de lÃ­nea
    $text = str_replace(["\r\n", "\r"], "\n", $text);
    $text = preg_replace('/\n{3,}/', "\n\n", $text);
    
    echo "  TamaÃ±o: " . number_format(strlen($text)) . " chars\n";

    if (strlen(trim($text)) < 50) {
        echo "<span class='warn'>  âš  Archivo vacÃ­o, saltando...</span>\n";
        $processedFiles[] = $filename;
    } else {
        // Chunking
        $chunks = chunkText($text, CHUNK_SIZE, CHUNK_OVERLAP);
        echo "  Chunks: " . count($chunks) . "\n";

        // Procesar en batches
        $batches = array_chunk($chunks, BATCH_SIZE);
        $fileChunks = 0;
        
        foreach ($batches as $batchIndex => $batch) {
            try {
                // Sanitizar cada texto para que sea JSON-safe
                $batchTexts = array_map(function($chunk) {
                    $t = $chunk['text'];
                    // Forzar encoding UTF-8 limpio
                    $t = mb_convert_encoding($t, 'UTF-8', 'UTF-8');
                    // Verificar que sea JSON-encodeable, si no, limpiar
                    if (json_encode($t) === false) {
                        $t = preg_replace('/[^\PC\s]/u', '', $t);
                    }
                    return $t;
                }, $batch);
                
                $vectors = $embeddings->embedBatch($batchTexts);
                
                $points = [];
                foreach ($batch as $i => $chunk) {
                    $points[] = [
                        'id' => $pointId++,
                        'vector' => $vectors[$i],
                        'payload' => [
                            'text' => $batchTexts[$i], // Usar texto sanitizado
                            'document_id' => pathinfo($filename, PATHINFO_FILENAME),
                            'document_name' => $filename,
                            'chunk_index' => $chunk['index'],
                            'section' => $chunk['section'] ?? ''
                        ]
                    ];
                }
                
                $qdrant->upsertPoints(COLLECTION_NAME, $points);
                $fileChunks += count($batch);
                $totalChunks += count($batch);
                
            } catch (Exception $e) {
                echo "<span class='err'>  âœ— Batch error: " . htmlspecialchars($e->getMessage()) . "</span>\n";
            }
            
            usleep(300000); // 300ms entre batches
        }
        
        echo "<span class='ok'>  âœ“ {$fileChunks} chunks indexados</span>\n";
        $processedFiles[] = $filename;
    }

    // Guardar progreso
    file_put_contents($progressFile, json_encode([
        'processed' => $processedFiles,
        'pointId' => $pointId,
        'totalChunks' => $totalChunks
    ]));

    echo "\n<span class='warn'>Recargando automÃ¡ticamente en 3 segundos...</span>";
    echo "</pre>";

} catch (Exception $e) {
    echo "<pre class='err'>âŒ ERROR: " . htmlspecialchars($e->getMessage()) . "</pre>";
    echo "<script>document.querySelector('meta[http-equiv]').remove();</script>";
}

echo "</body></html>";

// === Funciones ===

/**
 * Chunking inteligente por artÃ­culos para documentos legales
 * Detecta artÃ­culos, capÃ­tulos y secciones, evitando cortar unidades semÃ¡nticas
 */
function chunkText(string $text, int $targetTokens, int $overlap): array
{
    $charsPerToken = 4;
    $maxChars = $targetTokens * $charsPerToken;
    
    // Normalizar saltos de lÃ­nea y espacios
    $text = str_replace(["\r\n", "\r"], "\n", $text);
    $text = preg_replace('/[ \t]+/', ' ', $text);
    $text = preg_replace('/\n{3,}/', "\n\n", $text);
    
    // Patrones para detectar divisiones estructurales
    $patterns = [
        'capitulo' => '/^(CAPÃTULO|TÃTULO|PARTE|SECCIÃ“N)\s+([IVXLCDM]+|[0-9]+)[.:\s]/im',
        'articulo' => '/^((ArtÃ­culo|Art\.|ARTÃCULO)\s*([0-9]+))([.:\s]|$)/im',
    ];
    
    // Dividir por artÃ­culos primero
    $articles = [];
    $lines = explode("\n", $text);
    $currentArticle = ['header' => '', 'content' => '', 'type' => 'preambulo'];
    $currentChapter = '';
    
    foreach ($lines as $line) {
        $trimmedLine = trim($line);
        if (empty($trimmedLine)) {
            $currentArticle['content'] .= "\n";
            continue;
        }
        
        // Detectar capÃ­tulo/tÃ­tulo
        if (preg_match($patterns['capitulo'], $trimmedLine, $m)) {
            $currentChapter = $trimmedLine;
            $currentArticle['content'] .= $line . "\n";
            continue;
        }
        
        // Detectar nuevo artÃ­culo
        if (preg_match($patterns['articulo'], $trimmedLine, $m)) {
            // Guardar artÃ­culo anterior si tiene contenido
            if (!empty(trim($currentArticle['content']))) {
                $articles[] = $currentArticle;
            }
            // Iniciar nuevo artÃ­culo
            $currentArticle = [
                'header' => trim($m[1]),
                'content' => ($currentChapter ? $currentChapter . "\n" : '') . $line . "\n",
                'type' => 'articulo',
                'chapter' => $currentChapter
            ];
            continue;
        }
        
        // Agregar lÃ­nea al artÃ­culo actual
        $currentArticle['content'] .= $line . "\n";
    }
    
    // Guardar Ãºltimo artÃ­culo
    if (!empty(trim($currentArticle['content']))) {
        $articles[] = $currentArticle;
    }
    
    // Si no se detectaron artÃ­culos, usar el texto completo como un solo bloque
    if (empty($articles)) {
        $articles[] = [
            'header' => '',
            'content' => $text,
            'type' => 'documento',
            'chapter' => ''
        ];
    }
    
    // Agrupar artÃ­culos en chunks respetando lÃ­mite de tamaÃ±o
    $chunks = [];
    $index = 0;
    $buffer = '';
    $bufferHeaders = [];
    
    foreach ($articles as $article) {
        $articleText = trim($article['content']);
        $articleLen = strlen($articleText);
        
        // Si un artÃ­culo solo es muy grande, dividirlo
        if ($articleLen > $maxChars * 1.5) {
            // Guardar buffer actual si tiene contenido
            if (!empty($buffer)) {
                $chunks[] = [
                    'text' => trim($buffer),
                    'index' => $index++,
                    'section' => implode(', ', array_unique($bufferHeaders))
                ];
                $buffer = '';
                $bufferHeaders = [];
            }
            
            // Dividir artÃ­culo grande en sub-chunks
            $subChunks = splitLargeArticle($articleText, $maxChars, $article['header']);
            foreach ($subChunks as $subChunk) {
                $chunks[] = [
                    'text' => $subChunk,
                    'index' => $index++,
                    'section' => $article['header']
                ];
            }
            continue;
        }
        
        // Si agregar este artÃ­culo excede el lÃ­mite, crear nuevo chunk
        // Pero intentamos ser generosos: si el artÃ­culo es pequeÃ±o y el buffer no estÃ¡ gigante, lo metemos
        if (!empty($buffer) && (strlen($buffer) + $articleLen) > ($maxChars * 1.2)) {
            $chunks[] = [
                'text' => trim($buffer),
                'index' => $index++,
                'section' => implode(', ', array_unique($bufferHeaders))
            ];
            $buffer = '';
            $bufferHeaders = [];
        }
        
        // Agregar artÃ­culo al buffer
        $buffer .= $articleText . "\n\n";
        if (!empty($article['header'])) {
            $bufferHeaders[] = $article['header'];
        }
    }
    
    // Guardar Ãºltimo buffer
    if (!empty(trim($buffer))) {
        $chunks[] = [
            'text' => trim($buffer),
            'index' => $index++,
            'section' => implode(', ', array_unique($bufferHeaders))
        ];
    }
    
    return $chunks;
}

/**
 * Divide un artÃ­culo muy largo en sub-chunks por pÃ¡rrafos
 */
function splitLargeArticle(string $text, int $maxChars, string $header): array
{
    $paragraphs = preg_split('/\n\n+/', $text);
    $chunks = [];
    $buffer = $header ? $header . "\n" : '';
    
    foreach ($paragraphs as $para) {
        $para = trim($para);
        if (empty($para)) continue;
        
        if (!empty($buffer) && (strlen($buffer) + strlen($para)) > $maxChars) {
            $chunks[] = trim($buffer);
            $buffer = $header ? $header . "\n" : '';
        }
        
        $buffer .= $para . "\n\n";
    }
    
    if (!empty(trim($buffer))) {
        $chunks[] = trim($buffer);
    }
    
    return $chunks;
}
